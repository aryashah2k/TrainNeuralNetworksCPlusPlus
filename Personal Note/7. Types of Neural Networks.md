Types of neural networks

As you could see, machine learning has an extensive set of tools for pretty much any problem out there. Now let's zero in on neural networks. There are dozens of neural network types but I'd like to mention three very special types. First we have Hopfield neural networks, which have a fully connected architecture that is every neuron in the network sends its output to all the other neurons. 

It does have inputs and outputs. The inputs modify what's going on inside the network, including the output values. The logic behind this architecture is to let the neurons collectively perform the necessary computation in an emerging manner. That is the individual neurons aren't aware of the big picture but we can influence the whole network to produce the outputs we need given the inputs we feed into the network. Perhaps the best known category of neural networks is the Feedforward model, where we have a set of inputs, a series of layers of neurons with signals propagating forward until they reach the output. 

The success of this type of neural networks led to the development of a large family called deep neural networks which have a large number of neuron layers between the input and the output. One example of this evolution of deep neural networks are convolutional neural networks. An application I like very much is the deep dream generator which is a convolutional neural network that takes in a picture as input, then processes it through the many, many layers it has and finally shows you the modifications it has added to the original picture. 

These modifications, including formation it has collected over time from thousands of pictures it has seen before. So it seems the AI has been dreaming with your picture distorting it with interesting imagery in the process.