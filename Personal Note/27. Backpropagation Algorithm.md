The backpropagation algorithm

We are finally ready to see the backpropagation training algorithm. This is a general form of the delta rule. It has several requirements on the neuron model especially on the activation function. Don't worry the sigmoid makes it easy. The algorithm calculates all the weight updates throughout the network. This is done by propagating the error back through the layers. So here are the steps of the backpropagation algorithm to train a multilayer perception with one sample. 
One. Feed a sample to the network. 

Two. Calculate the mean squared error. 

Three. Calculate the error term of each output neuron. 

Four. Iteratively calculate the error terms in the hidden layers. Five. Applied the delta rule. And six. Adjust the weights. 

Now for your next challenge you'll have to write the backpropagation algorithm. That's why we're going to have a close look at each of these steps, because it's easy to get confused. For this example, I'll use a volunteer, which is this network with three inputs, four neurons in the first hidden layer, three neurons in the second one and two in the output layer. In my multi-layer perception class, these are layers zero through three respectively. As you can see, our neurons are explicitly showing their bias inputs because we'll use them in the algorithm. 

But remember that these inputs are rarely shown for the sake of simplicity. The bias is fixed at one. So don't confuse it with the bias input weights of the neurons. The first step is to run the network forward. So we feed a sample, say X equals 251. And let's say that that our network spitted out the output vector O equals 0.2 and 0.49. Our training sample included a vector of labels Y equals 01. That is the expected output for the first output neuron is zero and one for the second one. The second step is to calculate the mean squared error. This needs to be done at this point because we will assess the accuracy of the neural network later. And we are about to change its weights. Remember, the MSE is calculated on the outputs so we use Y and O. So subtracting vectors, Y minus O, we get minus 0.2 and 0.51. Squaring those values, we get 0.04 and 0.2601. Adding those values and dividing by two we finally get 0.15. That's the current state of the error metric for this network when receives X as input. 

We'll use this value later to review how well the network is learning. This is the error function that is undergoing gradient descent. Is 0.15 a large or small error? Bear with me when I say that it doesn't matter. What matters is reducing this number very much as we iterate. Step three is to calculate the output error terms. This is a third error metric and it's an intermediate error calculation that will be used for guessing how bad each neuron is doing. Notice that we're paying attention to the output layer. We'll later use these error terms to calculate the error terms in the hidden layers moving backwards through the network. That's the reason for the name backpropagation. 

Finally we'll know the error term for all of the neurons in the network and we will apply the delta rule to calculate the deltas and adjust the weights. So the error term for neuron K in the output layer is represented by lowercase delta sub-K. And it's related to the partial derivative of the error of the network with respect to each weight in that neuron. So delta sub-K equals O sub K, that's the output value of neuron K, times one minus O sub-K times the simple output error, Y sub-K minus O sub-K. Just so you know, this part is the derivative of the sigmoid function, which is very simple. And that's one of the main reasons to use the sigmoid function as an activation function for our neurons. So let's suppose we are interested in calculating the error term for output O1. 

Now let's zoom into the output layer for this example. To calculate lowercase delta sub-one, that's the error term for neuron number one in the output layer, we'll use O sub one and Y sub one in the equation. It's that simple. The fourth step is where the magic happens. Now we're going to calculate the error terms for the hidden layers. And we do this backwards. The previous step was done in the output layer. This step iterates from the last hidden layer, all the way to the first hidden layer to find an error term per neuron. 

Here's the equation for an error term lowercase delta sub-H. It's almost the same as for the output layer. The derivative of the sigmoid is still there but in the hidden layer, we have no idea about the error because we simply don't know what to expect from the intermediate neurons. So what we use instead is a sum of a product that includes the error terms in the neurons connected to this neurons output. These neurons are in the next layer, and we have just calculated their error terms lowercase delta sub-K, but that's not all we calculated in this sum. We must multiply these error terms by the weight of the input that's connected to the output of our neuron H. So let's zoom in again, to see what happens in the second neuron of the second hidden layer. This will be neuron one in the last hidden layer. So in the equation, H will be one. Actually, by lowercase delta one, I'm hiding the layer number. So let me be more specific in the diagram and call this lowercase delta 21. 

Meaning that this neuron is in layer two and it's neuron number one, the second neuron. To calculate lowercase delta sub 21, we'll need the usual derivative of the sigmoid times the weighted sum of the error terms. So these are the products we'll have to add for this neuron. Lowercase delta 30, or the error term of the output neuron zero times W01. That is the input weight one of this output neuron, we'll add this product with the product of lowercase delta 31 which is the error term of the other output neuron times W11, which is the weight of the input connected to our neuron 21. See why I called this magic. We are reacting to the error propagated back through the network in the right proportion by scaling the error terms with the weights. 

This means that errors with higher weights will take more of the blame and errors with lower weights will get less of the blame. Now, just for completeness, let's back up to layer one. So now in layer one, let's say we are interested in the third neuron that's lowercase delta two in this layer or its full name would be lowercase delta 12 as shown in the diagram. To calculate the sum, we'll have to multiply W02 with delta 20, W12 with delta 21, W22 with delta 22 and add these three products. It's all downhill from here. Step five is to apply the delta rule. 

Since we now have all of the error terms, the lowercase deltas, we may proceed to calculate the weight adjustments or uppercase deltas. So as the equation shows to compute the weight adjustment for an input J in a neuron I, we need to multiply the learning rate times the error term of the neuron I, times the input value J in neuron I. 

Great, now that we have the deltas we simply add them to the weights and we are done.