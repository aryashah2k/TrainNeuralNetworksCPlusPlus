Solution: Train your own SDR neural network

I made three applications for our segment display recognition neural network, all with a graphical user interface to allow you to see the neural network working as you tweak the input values. First, let me show you how the source files are organized. I left the NeuralNetworks folder for your convenience at the last point we left it, reporting the errors for the three models, along with the trained XOR and all previous tests. Now the GUI applications are all located in the SDRNN folder. Inside, you'll find the project folders called SDRNN_7to1, 7to10 and 7to7. 

To get your hands on this code, you'll need to download the Guice framework from guice.com. Make sure you read the instructions in the README file in the GitHub repository. However, if you don't feel like installing Guice, you may test the code with the executable files I placed in the Executables folder. There you'll find all three applications for Windows, macOS and Linux. Now, inside each project folder, you'll see the folder structure created by Guice. The projects are inside the Builds folder. 

There you'll file a Make file for Linux, an Xcode project for macOS and a Visual Studio project for Windows. Now let's look at the code for the 7to1 system, which is located under the Source folder. The code for our application is in SDRNN_7to1_GUI.h. Be advised that there's a lot of code to implement the graphical stuff, so you may be interested in two functions that deal with the neural network. These functions are present in all three implementations. The first is run_ann where the neural network is run once every time the user changes the input controls and the second one is train_ann where the back propagation happens. I'd rather show you the rest in the running application. So let's start with the 7to1 model. 

At the left, I created a set of seven sliders to act as the segments in the input. Moving them causes their color to simulate, becoming brighter or dimmer. At the right, we have parameters and results. You may enter the number of epochs to train next, which will happen when you press the train button. As results, the application displays the last reported training error, the number of epochs trained so far, the raw output value and the finally recognized number. I also included a reset button to start over. So let me train this network in steps of 100 epochs. Pay attention to the training error as it drops. I'll keep training until the error drops under 0.001. 

Now, none of these applications has a valid excuse for not recognizing a trained pattern. So all numbers from zero to nine must be correctly recognized. Let me show you a few patterns. Here's number one. Here's number four. And number nine. Okay, remember, I mentioned something wrong about this model? Now let me show you what it is. Let's enter the pattern for number zero. Yes, it's recognized correctly but let me slowly change the middle segment to turn it into an eight and back. Watch closely. Did you see that. 

Now ask yourself is it necessary to go through one, two, three, all the way to eight? Does changing the brightness of that segment make the pattern look more like a four or a five? Of course not. Our neural network had to satisfy that constraint and in doing so, it has sacrificed its ability to generalize. Now let's look at the one hot encoding model, the 7to10 network. Notice that we have the same controls except for the raw output, which is now showing as 10 raw outputs. So remember, the output with the highest value will be the one reported as the recognized number. Let me train this network for 1,000 epochs and then I'll train it in steps of 100 until I get an error of about 0.001. So again, let's see if it recognizes number three correctly. 

Number five. And number seven. And now for the zero to eight and back test, let me enter the pattern for zero. Now before I slide the middle segment, remember that there's no reason for the output to show anything other than zero and eight. So let's see it. There you have it. So now it feels like we're using a neural network free from the shackles of a forced sequence in the trained patterns. 

Finally, let's look at the 7to7 network. Now I'm not showing the raw outputs any longer but another set of sliders simulating an actual LED seven-segment display. This display will show us what the neural network infers from our input. Again, if our input is a valid pattern, there's no excuse to output anything other than that pattern because the network if very well trained. The interesting part is the output we get when we entered an invalid pattern. Let me train the network to an acceptable error. 

And now I want to show you a nice example of how the neural network struggles to get the incoming pattern right. This pattern at the left is very special because depending on the state of the bottom left and the bottom right segments, it could be a two or a three. If both segments are on, it's invalid, as well as when both segments are off. So at this point, both segments are off in the pattern at the left. And the output at the right is showing something between two and three. It's ambiguous. 

Notice as I slowly increase the brightness of the leftmost segment, the output become more confident of seeing a two and less confident of seeing a three. So you'll see those two sliders go in opposite directions in the display at the right. In fact, whenever I move either of those sliders, the sliders at the right will be having a tug of war towards the correct pattern. I don't expect this video to be enough for you, so please play around with the three systems, hopefully with your own version of MLP.CPP.

