Solution: Write your own backpropagation function

Step one is the simplest. We just run x through the network and assign the result to a new vector called outputs.

Step two is where we calculate the mean squared error. So first, I declare a vector to store the simple errors. I name that error. Then I'm calculating these simple errors and the sum of their squares in a for loop. And finally, I'm dividing this sum by the number of neurons in the last layer. 

Step three is done element by element in a for loop, just following the equation. 

Notice that the result goes to the last element in our d vector. In step four, first, I calculate the weighed sum of the forward error terms in a variable called fwd_error and then use that sum to calculate the current error term. Notice that the outputs are not recalculated. They are fetched from our values cache. All this is assigned to each element in the d vector, which contains the error terms. 

Steps five and six contain the most code but it's actually very simple. I goes through the layers, j goes through the neurons, and k goes through the inputs. That's why it goes from zero to the number of neurons in the previous layer plus one because of the bias weight. And that's what the body of the innermost loop is doing. If k is the last weight, we calculate the delta by multiplying the learning rate times the error term in that neuron times the bias term as the input because well, that's the input there. 

If it's not the bias weight we're checking with k, then we calculate the delta as the learning rate times the error term in that neuron times the actual input, which comes from our values cache indexed at the previous layer. That's it. Finally, I return the MSE. So let's see it working. Pay attention to the error values as they go down. Next, we have the weights. Notice that it came up with something other than the nand or and combination we designed earlier. Look at the values and the signs of the weights. This is surely a logical equivalent of that initial XOR and finally, we have the truth table. As you can see, we are practically getting the XOR behavior, meaning that our artificial brain has learned. It's alive. 

Now, this is my favorite part of the whole process. This plot shows the learning process of the XOR gate you just saw. I got this data by training an XOR just the way you saw and I copied the 30 error values reported in the terminal. I pasted them in a spreadsheet to finally make the plot. You should try it on your own and you'll get something very similar. As you can see, the plot shows how the error drops as the neural network learns epoch after epoch. These plots usually show a very subtle improvement in the error in the first iterations. 

But when the gradient descent starts to pay off, you'll see a dramatic drop after which the improvement is subtle again. That's just the law of diminishing returns working. And that's a smart way of telling when you should stop training. You don't want to waste your time getting less significant improvements or even worse, getting your neural network to over fit.