Solution: Logic gates with perceptrons


The values I came up with are 15 for both inputs and minus 10 for the bias. This way, any value of one in the inputs will make the weighted sum positive. Running it, we can see the or behavior. 

That is for zero, zero, we get a value very close to zero and the rest are greater than 0.99. If you like this exercise, you may want to create the Nant and nor Gates as an extra exercise. 

Great. So our perceptron can operate as we ask with the weights we write into it. Now we are ready to teach a behavior to our perceptron.